{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ðŸš€ For an interactive experience, head over to our [demo platform](https://var.vision/demo) and dive right in! ðŸŒŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[constructor]  ==== flash_if_available=True (0/16), fused_if_available=True (fusing_add_ln=0/16, fusing_mlp=0/16) ==== \n",
      "    [VAR config ] embed_dim=1024, num_heads=16, depth=16, mlp_ratio=4.0\n",
      "    [drop ratios ] drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0666667 (tensor([0.0000, 0.0044, 0.0089, 0.0133, 0.0178, 0.0222, 0.0267, 0.0311, 0.0356,\n",
      "        0.0400, 0.0444, 0.0489, 0.0533, 0.0578, 0.0622, 0.0667]))\n",
      "\n",
      "[init_weights] VAR with init_std=0.0180422\n",
      "prepare finished.\n"
     ]
    }
   ],
   "source": [
    "################## 1. Download checkpoints and build models\n",
    "import os\n",
    "import os.path as osp\n",
    "import torch, torchvision\n",
    "import random\n",
    "import numpy as np\n",
    "import PIL.Image as PImage, PIL.ImageDraw as PImageDraw\n",
    "setattr(torch.nn.Linear, 'reset_parameters', lambda self: None)     # disable default parameter init for faster speed\n",
    "setattr(torch.nn.LayerNorm, 'reset_parameters', lambda self: None)  # disable default parameter init for faster speed\n",
    "from models import VQVAE, build_vae_var\n",
    "\n",
    "MODEL_DEPTH = 16    # TODO: =====> please specify MODEL_DEPTH <=====\n",
    "assert MODEL_DEPTH in {16, 20, 24, 30}\n",
    "\n",
    "\n",
    "# download checkpoint\n",
    "hf_home = 'https://huggingface.co/FoundationVision/var/resolve/main'\n",
    "vae_ckpt, var_ckpt = 'vae_ch160v4096z32.pth', f'var_d{MODEL_DEPTH}.pth'\n",
    "if not osp.exists(vae_ckpt): os.system(f'wget {hf_home}/{vae_ckpt}')\n",
    "if not osp.exists(var_ckpt): os.system(f'wget {hf_home}/{var_ckpt}')\n",
    "\n",
    "# build vae, var\n",
    "patch_nums = (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if 'vae' not in globals() or 'var' not in globals():\n",
    "    vae, var = build_vae_var(\n",
    "        V=4096, Cvae=32, ch=160, share_quant_resi=4,    # hard-coded VQVAE hyperparameters\n",
    "        device=device, patch_nums=patch_nums,\n",
    "        num_classes=1000, depth=MODEL_DEPTH, shared_aln=False,\n",
    "    )\n",
    "\n",
    "# load checkpoints\n",
    "vae.load_state_dict(torch.load(vae_ckpt, map_location='cpu'), strict=True)\n",
    "var.load_state_dict(torch.load(var_ckpt, map_location='cpu'), strict=True)\n",
    "vae.eval(), var.eval()\n",
    "for p in vae.parameters(): p.requires_grad_(False)\n",
    "for p in var.parameters(): p.requires_grad_(False)\n",
    "print(f'prepare finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############################# 2. Sample with classifier-free guidance\n",
    "\n",
    "# set args\n",
    "seed = 0 #@param {type:\"number\"}\n",
    "torch.manual_seed(seed)\n",
    "num_sampling_steps = 250 #@param {type:\"slider\", min:0, max:1000, step:1} # IRRELEVANT -- variable not used\n",
    "cfg = 4 #@param {type:\"slider\", min:1, max:10, step:0.1}\n",
    "class_labels = (980, 980, 437, 437, 22, 22, 562, 562)  #@param {type:\"raw\"}\n",
    "more_smooth = False # True for more smooth output\n",
    "\n",
    "# seed\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# run faster\n",
    "tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = bool(tf32)\n",
    "torch.backends.cuda.matmul.allow_tf32 = bool(tf32)\n",
    "torch.set_float32_matmul_precision('high' if tf32 else 'highest')\n",
    "\n",
    "# sample\n",
    "B = len(class_labels)\n",
    "label_B: torch.LongTensor = torch.tensor(class_labels, device=device)\n",
    "# with torch.inference_mode():\n",
    "#     with torch.autocast('cuda', enabled=True, dtype=torch.float16, cache_enabled=True):    # using bfloat16 can be faster\n",
    "#         recon_B3HW = var.autoregressive_infer_cfg(B=B, label_B=label_B, cfg=cfg, top_k=900, top_p=0.95, g_seed=seed, more_smooth=more_smooth)\n",
    "\n",
    "# chw = torchvision.utils.make_grid(recon_B3HW, nrow=8, padding=0, pad_value=1.0)\n",
    "# chw = chw.permute(1, 2, 0).mul_(255).cpu().numpy()\n",
    "# chw = PImage.fromarray(chw.astype(np.uint8))\n",
    "# chw.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chw = torchvision.utils.make_grid(recon_B3HW, nrow=8, padding=0, pad_value=1.0)\n",
    "# chw = chw.permute(1, 2, 0).mul_(255).cpu().numpy()\n",
    "# chw = PImage.fromarray(chw.astype(np.uint8))\n",
    "# chw.show()\n",
    "# recon_B3HW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimized_image = torch.rand_like(recon_B3HW, requires_grad=True)\n",
    "# image_pyramid = vae.img_to_idxBl(optimized_image, patch_nums)\n",
    "\n",
    "# image_pyramid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructed = vae.idxBl_to_img(image_pyramid, same_shape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstructed[6].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = recon_B3HW\n",
    "x = torch.rand(8, 3, 256, 256)\n",
    "\n",
    "f = vae.quant_conv(vae.encoder(x))\n",
    "\n",
    "# ls_f_hat_BChw = vae.quantize.f_to_idxBl_or_fhat(f, to_fhat=False, v_patch_nums=patch_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "patch_nums = (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)\n",
    "coarsness_step = 4\n",
    "\n",
    "quant_pyramid, f_hat = vae.quantize.f_to_quant_pyramid_and_f_hat(f, patch_nums, coarsness_step)\n",
    "\n",
    "residual = f - f_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(quant_pyramid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the pyramid as the input for transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_residual = var.autoregressive_single_step_prediction(\n",
    "    quant_pyramid=quant_pyramid, \n",
    "    f_hat=f_hat, \n",
    "    label_B=label_B, \n",
    "    cfg=cfg, \n",
    "    top_k=900, \n",
    "    top_p=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 16, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 16, 16])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_residual.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation POC in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimisation_loss(f, coarsness_step):\n",
    "    quant_pyramid, f_hat = vae.quantize.f_to_quant_pyramid_and_f_hat(f, patch_nums, coarsness_step)\n",
    "\n",
    "    f_residual = f - f_hat\n",
    "\n",
    "    predicted_residual = var.autoregressive_single_step_prediction(\n",
    "        quant_pyramid=quant_pyramid, \n",
    "        f_hat=f_hat, \n",
    "        label_B=label_B, \n",
    "        cfg=cfg, \n",
    "        top_k=900, \n",
    "        top_p=0.95)\n",
    "\n",
    "    return F.mse_loss(predicted_residual, f_residual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 1, loss: 0.004371508955955505\n",
      "coarsness_step: 1, loss: 0.0003481769817881286\n",
      "coarsness_step: 1, loss: 0.00036811825702898204\n",
      "coarsness_step: 1, loss: 0.00014163559535518289\n",
      "coarsness_step: 1, loss: 0.00015670272114221007\n",
      "coarsness_step: 1, loss: 0.00011510938202263787\n",
      "coarsness_step: 1, loss: 9.264543768949807e-05\n",
      "coarsness_step: 1, loss: 6.400592974387109e-05\n",
      "coarsness_step: 1, loss: 3.6390963941812515e-05\n",
      "coarsness_step: 1, loss: 1.6867006706888787e-05\n",
      "coarsness_step: 2, loss: 0.0005777326296083629\n",
      "coarsness_step: 2, loss: 0.0005680759786628187\n",
      "coarsness_step: 2, loss: 0.0006122048944234848\n",
      "coarsness_step: 2, loss: 0.0005135508254170418\n",
      "coarsness_step: 2, loss: 0.0003322355914860964\n",
      "coarsness_step: 2, loss: 0.0001490399445174262\n",
      "coarsness_step: 2, loss: 0.0001059482601704076\n",
      "coarsness_step: 2, loss: 5.8833087678067386e-05\n",
      "coarsness_step: 2, loss: 4.348806032794528e-05\n",
      "coarsness_step: 2, loss: 1.7639913494349457e-05\n",
      "coarsness_step: 3, loss: 0.00029077508952468634\n",
      "coarsness_step: 3, loss: 0.00038187881000339985\n",
      "coarsness_step: 3, loss: 0.0006499324808828533\n",
      "coarsness_step: 3, loss: 0.0009985914221033454\n",
      "coarsness_step: 3, loss: 0.0008054088684730232\n",
      "coarsness_step: 3, loss: 0.0007235357770696282\n",
      "coarsness_step: 3, loss: 0.0006074735429137945\n",
      "coarsness_step: 3, loss: 0.0003904538752976805\n",
      "coarsness_step: 3, loss: 0.0002759772469289601\n",
      "coarsness_step: 3, loss: 0.00011615872062975541\n",
      "coarsness_step: 4, loss: 0.00275896186940372\n",
      "coarsness_step: 4, loss: 0.0036486955359578133\n",
      "coarsness_step: 4, loss: 0.0032278418075293303\n",
      "coarsness_step: 4, loss: 0.0025476005394011736\n",
      "coarsness_step: 4, loss: 0.002129422966390848\n",
      "coarsness_step: 4, loss: 0.0012777227675542235\n",
      "coarsness_step: 4, loss: 0.0009965829085558653\n",
      "coarsness_step: 4, loss: 0.0006378889665938914\n",
      "coarsness_step: 4, loss: 0.0003851410001516342\n",
      "coarsness_step: 4, loss: 0.000164808239787817\n",
      "coarsness_step: 5, loss: 0.00436823396012187\n",
      "coarsness_step: 5, loss: 0.004785729572176933\n",
      "coarsness_step: 5, loss: 0.006223223637789488\n",
      "coarsness_step: 5, loss: 0.004688213113695383\n",
      "coarsness_step: 5, loss: 0.003649128135293722\n",
      "coarsness_step: 5, loss: 0.002614089986309409\n",
      "coarsness_step: 5, loss: 0.0018348466837778687\n",
      "coarsness_step: 5, loss: 0.0015406926395371556\n",
      "coarsness_step: 5, loss: 0.000818293949123472\n",
      "coarsness_step: 5, loss: 0.000429572508437559\n",
      "coarsness_step: 6, loss: 0.014657756313681602\n",
      "coarsness_step: 6, loss: 0.013967570848762989\n",
      "coarsness_step: 6, loss: 0.014613418839871883\n",
      "coarsness_step: 6, loss: 0.010980289429426193\n",
      "coarsness_step: 6, loss: 0.009450024925172329\n",
      "coarsness_step: 6, loss: 0.006651891395449638\n",
      "coarsness_step: 6, loss: 0.00496450811624527\n",
      "coarsness_step: 6, loss: 0.004018991254270077\n",
      "coarsness_step: 6, loss: 0.0022537687327712774\n",
      "coarsness_step: 6, loss: 0.0011593338567763567\n",
      "coarsness_step: 7, loss: 0.032910846173763275\n",
      "coarsness_step: 7, loss: 0.03438190370798111\n",
      "coarsness_step: 7, loss: 0.02810387685894966\n",
      "coarsness_step: 7, loss: 0.024747619405388832\n",
      "coarsness_step: 7, loss: 0.01975231245160103\n",
      "coarsness_step: 7, loss: 0.01642642170190811\n",
      "coarsness_step: 7, loss: 0.012148239649832249\n",
      "coarsness_step: 7, loss: 0.009043295867741108\n",
      "coarsness_step: 7, loss: 0.005493481643497944\n",
      "coarsness_step: 7, loss: 0.0022641175892204046\n",
      "coarsness_step: 8, loss: 0.09927000850439072\n",
      "coarsness_step: 8, loss: 0.09944450110197067\n",
      "coarsness_step: 8, loss: 0.08305493742227554\n",
      "coarsness_step: 8, loss: 0.06656169146299362\n",
      "coarsness_step: 8, loss: 0.05921033397316933\n",
      "coarsness_step: 8, loss: 0.04484892636537552\n",
      "coarsness_step: 8, loss: 0.03232596442103386\n",
      "coarsness_step: 8, loss: 0.02430454082787037\n",
      "coarsness_step: 8, loss: 0.014366725459694862\n",
      "coarsness_step: 8, loss: 0.0068673924542963505\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f = torch.rand([2, 32, 16, 16], requires_grad=True)\n",
    "\n",
    "class_labels = (22, 562)  #@param {type:\"raw\"}\n",
    "label_B: torch.LongTensor = torch.tensor(class_labels, device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam([f], lr=0.1)\n",
    "\n",
    "steps_per_coarsness = 100\n",
    "\n",
    "for coarsness_step in range(1, len((patch_nums)) - 1):\n",
    "    for i in range(steps_per_coarsness):\n",
    "        optimizer.zero_grad()\n",
    "        loss = get_optimisation_loss(f, coarsness_step)\n",
    "        loss*= patch_nums[coarsness_step]**2 / patch_nums[len(patch_nums)-1]**2\n",
    "        loss*= (steps_per_coarsness - i) / steps_per_coarsness\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f'coarsness_step: {coarsness_step}, loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = vae.fhat_to_img(f).add_(1).mul_(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(9189) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(9190) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "chw = torchvision.utils.make_grid(image, nrow=8, padding=0, pad_value=1.0)\n",
    "chw = chw.permute(1, 2, 0).mul_(255).cpu().numpy()\n",
    "chw = PImage.fromarray(chw.astype(np.uint8))\n",
    "chw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random coarsness step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/400 [00:05<34:39,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 4, loss: 0.09834317117929459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 11/400 [03:48<7:03:56, 65.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 7, loss: 0.10095315426588058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|â–Œ         | 21/400 [04:00<19:12,  3.04s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 5, loss: 0.015652334317564964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 31/400 [16:47<5:45:27, 56.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 5, loss: 0.009880476631224155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|â–ˆ         | 41/400 [17:23<26:52,  4.49s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 4, loss: 0.006207524798810482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|â–ˆâ–Ž        | 51/400 [17:39<08:37,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 2, loss: 0.0025906700175255537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|â–ˆâ–Œ        | 61/400 [18:07<17:46,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 7, loss: 0.018752446398139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|â–ˆâ–Š        | 71/400 [18:24<09:02,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 5, loss: 0.0070991660468280315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|â–ˆâ–ˆ        | 81/400 [18:39<09:29,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 6, loss: 0.00950113870203495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|â–ˆâ–ˆâ–Ž       | 91/400 [18:58<04:56,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 1, loss: 0.0011801017681136727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 101/400 [19:17<13:33,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 7, loss: 0.02104043960571289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|â–ˆâ–ˆâ–Š       | 111/400 [19:31<05:30,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 3, loss: 0.00307333841919899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|â–ˆâ–ˆâ–ˆ       | 121/400 [19:51<11:12,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 8, loss: 0.03673836961388588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 131/400 [20:00<03:04,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 5, loss: 0.0057668788358569145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 141/400 [20:12<03:28,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 2, loss: 0.002143984194844961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 151/400 [20:27<04:23,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 5, loss: 0.0038930713199079037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 161/400 [20:51<07:53,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 7, loss: 0.012571165338158607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 171/400 [21:13<10:25,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 8, loss: 0.027296559885144234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 181/400 [21:26<03:53,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 1, loss: 0.002047841204330325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 191/400 [21:35<01:43,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 2, loss: 0.003128730459138751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 201/400 [21:46<03:29,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 1, loss: 0.0016092625446617603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 211/400 [21:59<02:30,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 4, loss: 0.0026412273291498423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 221/400 [22:08<01:54,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 2, loss: 0.0027278035413473845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 231/400 [22:21<04:43,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 6, loss: 0.004148900043219328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 241/400 [22:35<03:48,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 1, loss: 0.0016260698903352022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 251/400 [22:52<02:56,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 1, loss: 0.0018258620984852314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 261/400 [23:07<03:01,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 6, loss: 0.007293058093637228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 271/400 [23:27<05:12,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 8, loss: 0.017124123871326447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 281/400 [23:45<03:44,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 6, loss: 0.005782019346952438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 291/400 [23:58<02:24,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 6, loss: 0.004763308446854353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 301/400 [24:14<03:01,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 5, loss: 0.002259922446683049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 311/400 [24:26<01:22,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 4, loss: 0.0020377703476697206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 321/400 [24:41<02:18,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 6, loss: 0.0020869560539722443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 331/400 [24:54<02:33,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 8, loss: 0.009092291817069054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 341/400 [25:07<00:56,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 1, loss: 0.0007735262042842805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 351/400 [25:20<01:04,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 6, loss: 0.0013377207797020674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 361/400 [25:35<00:54,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 6, loss: 0.0010890368139371276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 371/400 [25:58<01:17,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 7, loss: 0.0014432725729420781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 381/400 [26:15<00:23,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 4, loss: 0.0003595100424718112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 391/400 [26:28<00:09,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coarsness_step: 4, loss: 0.00018257004558108747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [26:41<00:00,  4.00s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "f = torch.randn([8, 32, 16, 16], requires_grad=True) \n",
    "\n",
    "class_labels = (980, 980, 437, 437, 22, 22, 562, 562)  #@param {type:\"raw\"}\n",
    "label_B: torch.LongTensor = torch.tensor(class_labels, device=device)\n",
    "\n",
    "optimizer = torch.optim.Adam([f], lr=0.1)\n",
    "total_steps = 400\n",
    "\n",
    "for i in tqdm(range(total_steps), total=total_steps):\n",
    "    coarsness_step = np.random.randint(1, len((patch_nums)) - 1)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = get_optimisation_loss(f, coarsness_step)\n",
    "\n",
    "    loss*= patch_nums[coarsness_step]**2 / patch_nums[len(patch_nums)-1]**2\n",
    "    loss*= (total_steps - i) / total_steps # linearly decrease the loss weight\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f'coarsness_step: {coarsness_step}, loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = vae.fhat_to_img(f).add_(1).mul_(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(92571) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(92584) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    }
   ],
   "source": [
    "chw = torchvision.utils.make_grid(image, nrow=8, padding=0, pad_value=1.0)\n",
    "chw = chw.permute(1, 2, 0).mul_(255).cpu().numpy()\n",
    "chw = PImage.fromarray(chw.astype(np.uint8))\n",
    "chw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-var",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
